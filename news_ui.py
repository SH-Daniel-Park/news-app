# -*- coding: utf-8 -*-
import io
import json
import pandas as pd
import streamlit as st

from news_aggregator import (
    collect_articles,
    enrich_with_content,
    filter_by_publishers,
    extract_domain,
    DEFAULT_RSS_FEEDS,
)

st.set_page_config(page_title="ğŸ“° ë‰´ìŠ¤ í‚¤ì›Œë“œ ìˆ˜ì§‘/ìš”ì•½ ëŒ€ì‹œë³´ë“œ", layout="wide")

st.title("ğŸ“° ë‰´ìŠ¤ í‚¤ì›Œë“œ ìˆ˜ì§‘/ìš”ì•½ ëŒ€ì‹œë³´ë“œ")
st.caption("í‚¤ì›Œë“œë¡œ ì—¬ëŸ¬ ì–¸ë¡  ê¸°ì‚¬ë¥¼ ëª¨ì•„ë³´ê³ , ë³¸ë¬¸/ìš”ì•½/í‚¤ì›Œë“œë¥¼ í•¨ê»˜ í™•ì¸í•˜ì„¸ìš”.")

# --- ì…ë ¥ ì˜ì—­ (ì¢Œì¸¡ ì‚¬ì´ë“œë°”) -------------------------------------------------
with st.sidebar:
    st.header("ê²€ìƒ‰ ì„¤ì •")
    query = st.text_input("ê²€ìƒ‰ í‚¤ì›Œë“œ", placeholder="ì˜ˆ) ì¬ì •ì •ì±…, ë°˜ë„ì²´, í™˜ìœ¨ ê¸‰ë“±")
    max_results = st.slider("ìµœëŒ€ ê¸°ì‚¬ ìˆ˜", 10, 300, 60, step=10)
    newsapi_key = st.text_input("NewsAPI í‚¤ (ì„ íƒ)", type="password")

    st.markdown("---")
    st.subheader("RSS ì†ŒìŠ¤")
    use_default_rss = st.checkbox(
        "ìƒ˜í”Œ ê¸°ë³¸ RSS ì‚¬ìš©",
        True,
        help="ìš´ì˜ ì‹œì—ëŠ” ìµœì‹  RSS ì£¼ì†Œë¥¼ feeds.txtë¡œ ê´€ë¦¬í•˜ëŠ” ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤."
    )
    uploaded_feeds = st.file_uploader("feeds.txt ì—…ë¡œë“œ (ì¤„ë‹¹ í•˜ë‚˜ì˜ RSS URL)", type=["txt"])

    rss_feeds = []
    if use_default_rss:
        rss_feeds.extend(DEFAULT_RSS_FEEDS)
    if uploaded_feeds is not None:
        try:
            txt = uploaded_feeds.read().decode("utf-8", errors="ignore")
            for line in txt.splitlines():
                url = line.strip()
                if url and not url.startswith("#"):
                    rss_feeds.append(url)
        except Exception:
            st.warning("feeds.txtë¥¼ ì½ëŠ” ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")

    st.markdown("---")
    st.subheader("ì½˜í…ì¸  ì²˜ë¦¬")
    do_fetch_text = st.checkbox("ê¸°ì‚¬ ë³¸ë¬¸ ìˆ˜ì§‘ (í¬ë¡¤ë§)", True)
    do_summarize = st.checkbox("ìš”ì•½ ìƒì„±", True)
    summary_len = st.slider("ìš”ì•½ ë¬¸ì¥ ìˆ˜", 2, 6, 3)
    do_keywords = st.checkbox("í‚¤ì›Œë“œ(í˜•íƒœì†Œ) ì¶”ì¶œ", True)

    st.markdown("---")
    run = st.button("ğŸ” ìˆ˜ì§‘ ì‹œì‘", use_container_width=True)

# --- ìˆ˜ì§‘ ì‹¤í–‰ ----------------------------------------------------------------
if run:
    if not query.strip():
        st.warning("í‚¤ì›Œë“œë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
        st.stop()

    with st.spinner("ê¸°ì‚¬ë¥¼ ìˆ˜ì§‘í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
        raw = collect_articles(
            query=query,
            max_results=max_results,
            newsapi_key=newsapi_key.strip() or None,
            rss_feeds=rss_feeds if rss_feeds else None,
        )

    if not raw:
        st.info("ê´€ë ¨ ê¸°ì‚¬ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. í‚¤ì›Œë“œë¥¼ ë°”ê¿”ë³´ê±°ë‚˜ ê²°ê³¼ ìˆ˜ë¥¼ ëŠ˜ë ¤ë³´ì„¸ìš”.")
        st.stop()

    # ì–¸ë¡ ì‚¬ í•„í„° UI (ìˆ˜ì§‘ ê²°ê³¼ ê¸°ë°˜)
    publishers = sorted(list({(it.get("publisher") or extract_domain(it["link"]) or "").strip()
                              for it in raw if it.get("link")}))
    with st.expander("ì–¸ë¡ ì‚¬/ë„ë©”ì¸ í•„í„°"):
        allow = st.multiselect(
            "í¬í•¨í•  ì–¸ë¡ ì‚¬ ë˜ëŠ” ë„ë©”ì¸ ì„ íƒ (ë¯¸ì„ íƒ ì‹œ ì „ì²´)",
            options=publishers, default=[]
        )

    filtered = filter_by_publishers(raw, allow_publishers=allow)

    if not filtered:
        st.info("í•„í„° ì¡°ê±´ì— ë§ëŠ” ê¸°ì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤. í•„í„°ë¥¼ ë¹„ìš°ê±°ë‚˜ ë³€ê²½í•´ ë³´ì„¸ìš”.")
        st.stop()

    # ë³¸ë¬¸/ìš”ì•½/í‚¤ì›Œë“œ ì¶”ê°€
    if do_fetch_text or do_summarize or do_keywords:
        with st.spinner("ë³¸ë¬¸/ìš”ì•½/í‚¤ì›Œë“œë¥¼ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
            enriched = enrich_with_content(
                filtered,
                do_fetch_text=do_fetch_text,
                do_summarize=do_summarize,
                do_keywords=do_keywords,
                summary_sentences=summary_len,
            )
    else:
        enriched = filtered

    # í‘œë¡œ í‘œì‹œ -----------------------------------------------------------------
    df = pd.DataFrame(enriched)

    # í‘œì‹œìš© ì—´ ì •ë¦¬
    display_cols = ["title", "publisher", "published_at", "link"]
    if do_summarize:
        display_cols.append("summary")
    if do_keywords:
        display_cols.append("keywords")

    st.success(f"ì´ {len(df)}ê±´ì˜ ê¸°ì‚¬ë¥¼ í™•ë³´í–ˆìŠµë‹ˆë‹¤.")

    # ğŸ”— ë§í¬ë¥¼ í´ë¦­ ê°€ëŠ¥í•˜ê²Œ: LinkColumn ì‚¬ìš© (í•œ ë²ˆ í´ë¦­ìœ¼ë¡œ ìƒˆ íƒ­ ì´ë™)
    st.dataframe(
        df[display_cols],
        use_container_width=True,
        height=520,
        column_config={
            "link": st.column_config.LinkColumn(
                "ë§í¬",
                display_text="ë°”ë¡œê°€ê¸°"
            ),
            "title": st.column_config.TextColumn("ì œëª©", width="large"),
            "publisher": st.column_config.TextColumn("ì–¸ë¡ ì‚¬"),
            "published_at": st.column_config.TextColumn("ë°œí–‰ì‹œê°"),
            # summary/keywordsëŠ” ìë™ ë Œë”ë§
        }
    )

    # ìƒì„¸ ë³´ê¸° -----------------------------------------------------------------
    st.markdown("### ì„¸ë¶€ ê¸°ì‚¬ ë³´ê¸°")
    titles = ["(ì„ íƒ)"] + df["title"].tolist()
    sel = st.selectbox("ë³¸ë¬¸/ìš”ì•½/í‚¤ì›Œë“œë¥¼ í™•ì¸í•  ê¸°ì‚¬", options=titles, index=0)
    if sel != "(ì„ íƒ)":
        row = df[df["title"] == sel].iloc[0]
        st.markdown(f"**ì–¸ë¡ ì‚¬**: {row.get('publisher','')}  |  **ë°œí–‰**: {row.get('published_at','')}")
        st.markdown(f"**ì›ë¬¸ ë§í¬**: {row.get('link','')}")
        if do_fetch_text:
            st.markdown("#### ë³¸ë¬¸")
            st.write(row.get("content", "") or "ë³¸ë¬¸ì„ ìˆ˜ì§‘í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        if do_summarize:
            st.markdown("#### ìš”ì•½")
            st.write(row.get("summary", "") or "-")
        if do_keywords:
            st.markdown("#### í‚¤ì›Œë“œ")
            kw = row.get("keywords", []) or []
            st.write(", ".join(kw) if kw else "-")

    # CSV ë‹¤ìš´ë¡œë“œ ---------------------------------------------------------------
    st.markdown("---")
    st.subheader("ê²°ê³¼ ë‹¤ìš´ë¡œë“œ")
    csv_bytes = df.to_csv(index=False, encoding="utf-8-sig").encode("utf-8-sig")
    st.download_button(
        "CSVë¡œ ë‹¤ìš´ë¡œë“œ",
        data=csv_bytes,
        file_name=f"{query}_news.csv",
        mime="text/csv",
        use_container_width=True,
    )

else:
    st.info("ì¢Œì¸¡ ì‚¬ì´ë“œë°”ì—ì„œ í‚¤ì›Œë“œë¥¼ ì…ë ¥í•˜ê³  **ìˆ˜ì§‘ ì‹œì‘**ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.")
